{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff19f960-b9d2-41f7-99b3-21c43c403504",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9fa20dd-8655-457c-a2c4-08b987586e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34martifacts\u001b[0m/        dvc.yaml  params.yaml       setup.py     \u001b[01;34mvenv\u001b[0m/\n",
      "\u001b[01;34mChicken_project\u001b[0m/  LICENSE   README.md         \u001b[01;34msrc\u001b[0m/\n",
      "\u001b[01;34mconfig\u001b[0m/           \u001b[01;34mlogs\u001b[0m/     requirements.txt  template.py\n",
      "\u001b[01;31mdata.zip\u001b[0m          main.py   \u001b[01;34mresearch\u001b[0m/         \u001b[01;34mtemplates\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72233e-bba5-4941-a378-ef9abe68eb34",
   "metadata": {},
   "source": [
    "# Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196fc61b-227f-494b-ad1c-826bc7528aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    trained_model_path: Path\n",
    "    dataframe_path: Path\n",
    "    test_batch_size: int\n",
    "    batch_size: int\n",
    "    img_size: list\n",
    "    channels: int\n",
    "    color: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e684d-055f-4c24-b59c-c50fe2c20110",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac5c460-3cde-466b-a9c3-21fdcf6376c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14a55522-c2d0-40fa-ba0b-ac6c1b2bda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        config = self.config.evaluation\n",
    "        eval_config = EvaluationConfig(\n",
    "            trained_model_path=config.trained_model_path,\n",
    "            dataframe_path=config.dataframe_path,\n",
    "            test_batch_size=self.params.test_batch_size,\n",
    "            batch_size=self.params.batch_size,\n",
    "            img_size=self.params.img_size,\n",
    "            channels=self.params.channels,\n",
    "            color=self.params.color\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dadd139-2220-4b64-96c7-d672f0d385a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-10 14:30:38,383: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-12-10 14:30:38,386: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-10 14:30:38,388: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvaluationConfig(trained_model_path='artifacts/training/trained_model.keras', dataframe_path='artifacts/training', test_batch_size=40, batch_size=40, img_size=BoxList([224, 224]), channels=3, color='rgb')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfigurationManager().get_evaluation_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d62167-338b-42b9-b8ab-ea110c6ec917",
   "metadata": {},
   "source": [
    "# Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b94e389-5379-4b8e-9390-418ee925d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4300a85-f877-4e6b-a7e5-cde17fb3e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.ts_length = None\n",
    "        \n",
    "    def load_train_valid_test_df(self):\n",
    "          # load generators\n",
    "        path = os.path.join(self.config.dataframe_path,'train_df.pkl')\n",
    "        with open(path, 'rb') as f:\n",
    "            train_df = pickle.load(f)\n",
    "\n",
    "        path = os.path.join(self.config.dataframe_path,'valid_df.pkl')\n",
    "        with open(path, 'rb') as f:\n",
    "            valid_df = pickle.load(f)\n",
    "\n",
    "        path = os.path.join(self.config.dataframe_path,'test_df.pkl')\n",
    "        with open(path, 'rb') as f:\n",
    "            test_df = pickle.load(f)\n",
    "\n",
    "        self.ts_length = len(test_df)\n",
    "\n",
    "        return train_df, valid_df, test_df\n",
    "\n",
    "        \n",
    "    def create_train_valid_test_generator(self, train_df, valid_df, test_df):\n",
    "        '''\n",
    "        This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n",
    "        Image data generator converts images into tensors. \n",
    "        '''\n",
    "\n",
    "        # define model parameters\n",
    "        batch_size = self.config.batch_size\n",
    "        img_size = self.config.img_size\n",
    "        channels = self.config.channels\n",
    "        color = self.config.color\n",
    "        img_shape = (img_size[0], img_size[1], channels)\n",
    "    \n",
    "        ts_length = len(test_df)\n",
    "        test_batch_size = self.config.batch_size\n",
    "        test_steps = ts_length // test_batch_size\n",
    "        # This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n",
    "        def scalar(img):\n",
    "            return img\n",
    "    \n",
    "        tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
    "        ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
    "    \n",
    "        train_gen = tr_gen.flow_from_dataframe(train_df, x_col = 'filepaths', y_col = 'labels', target_size= img_size, class_mode = \"binary\",\n",
    "                                              color_mode= color, shuffle= False, batch_size= batch_size)\n",
    "        valid_gen = ts_gen.flow_from_dataframe(valid_df, x_col = 'filepaths', y_col = 'labels', target_size= img_size, class_mode = \"binary\",\n",
    "                                              color_mode= color, shuffle= False, batch_size= batch_size)\n",
    "         # Note: we will use custom test_batch_size, and make shuffle= false\n",
    "        test_gen = ts_gen.flow_from_dataframe(test_df, x_col = 'filepaths', y_col = 'labels', target_size= img_size, class_mode = \"binary\",\n",
    "                                             color_mode= color, shuffle= False, batch_size= test_batch_size)\n",
    "        self.train_gen = train_gen\n",
    "        self.valid_gen = valid_gen\n",
    "        self.test_gen = test_gen\n",
    "        \n",
    "        return train_gen, valid_gen, test_gen\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "\n",
    "    def evaluation(self):\n",
    "        model = self.load_model(self.config.trained_model_path)\n",
    "        \n",
    "        ts_length = self.ts_length\n",
    "        test_batch_size = self.config.batch_size\n",
    "        test_steps = ts_length // test_batch_size\n",
    "        \n",
    "        train_score = model.evaluate(self.train_gen, steps= test_steps, verbose= 1)\n",
    "        valid_score = model.evaluate(self.valid_gen, steps= test_steps, verbose= 1)\n",
    "        test_score = model.evaluate(self.test_gen, steps= test_steps, verbose= 1)\n",
    "        \n",
    "        print(\"Train Loss: \", train_score[0])\n",
    "        print(\"Train Accuracy: \", train_score[1])\n",
    "        print('-' * 20)\n",
    "        print(\"Validation Loss: \", valid_score[0])\n",
    "        print(\"Validation Accuracy: \", valid_score[1])\n",
    "        print('-' * 20)\n",
    "        print(\"Test Loss: \", test_score[0])\n",
    "        print(\"Test Accuracy: \", test_score[1])\n",
    "\n",
    "    \n",
    "        scores = {\"Train Loss\": train_score[0], \"Train Accuracy:\": train_score[1],\n",
    "                 \"Validation Loss\": valid_score[0], \"Validation Accuracy:\": valid_score[1],\n",
    "                 \"Test Loss\": test_score[0], \"Test Accuracy:\": test_score[1]}\n",
    "        \n",
    "        save_json(path=Path(\"scores.json\"), data=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96993a88-ad1d-49a2-87af-3251f7c78c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-10 14:37:00,463: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-12-10 14:37:00,467: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-10 14:37:00,468: INFO: common: created directory at: artifacts]\n",
      "Found 3904 validated image filenames belonging to 2 classes.\n",
      "Found 488 validated image filenames belonging to 2 classes.\n",
      "Found 488 validated image filenames belonging to 2 classes.\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 0.0484 - accuracy: 0.9896\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 0.0746 - accuracy: 0.9708\n",
      "12/12 [==============================] - 3s 259ms/step - loss: 0.1858 - accuracy: 0.9438\n",
      "Train Loss:  0.0483812615275383\n",
      "Train Accuracy:  0.9895833134651184\n",
      "--------------------\n",
      "Validation Loss:  0.07457593083381653\n",
      "Validation Accuracy:  0.9708333611488342\n",
      "--------------------\n",
      "Test Loss:  0.18583659827709198\n",
      "Test Accuracy:  0.9437500238418579\n",
      "[2023-12-10 14:37:12,054: INFO: common: json file saved at: scores.json]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "val_config = config.get_evaluation_config()\n",
    "evaluation = Evaluation(val_config)\n",
    "train_df, valid_df, test_df = evaluation.load_train_valid_test_df()\n",
    "evaluation.create_train_valid_test_generator(train_df, valid_df, test_df)\n",
    "evaluation.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fad037-151a-4cee-a968-5e85f4f28758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loss:  0.03094664216041565\n",
    "# Train Accuracy:  0.9937499761581421\n",
    "# --------------------\n",
    "# Validation Loss:  0.07457593083381653\n",
    "# Validation Accuracy:  0.9708333611488342\n",
    "# --------------------\n",
    "# Test Loss:  0.18583659827709198\n",
    "# Test Accuracy:  0.9437500238418579"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
